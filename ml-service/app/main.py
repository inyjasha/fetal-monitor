from datetime import datetime
import os
import sys
import asyncio
import logging
from typing import Dict, List, Optional, Any
import json
import tempfile
import numpy as np
import pandas as pd
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Query, Request
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

import os
from fastapi import UploadFile, File, Form
import uuid
from pathlib import Path

import zipfile
import shutil
from app.ml_metrics import simple_metrics

# Ð˜ÐœÐŸÐžÐ Ð¢Ð« Ð”Ð›Ð¯ ML ÐœÐ•Ð¢Ð Ð˜Ðš
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score, 
    classification_report, 
    confusion_matrix,
    roc_auc_score,
    mean_squared_error,
    mean_absolute_error,
    r2_score
)
from sklearn.preprocessing import label_binarize
import scipy.stats as stats

logger = logging.getLogger("simple-metrics")

bpm_history = []
prediction_history = []

# --------------------
# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿ÑƒÑ‚ÐµÐ¹
# --------------------

# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # Ð¿Ð°Ð¿ÐºÐ° app
ML_SERVICE_DIR = os.path.dirname(BASE_DIR)  # Ð¿Ð°Ð¿ÐºÐ° ml-service
PROJECT_ROOT = os.path.dirname(ML_SERVICE_DIR)  # Ð¿Ð°Ð¿ÐºÐ° fetal-monitor

# ÐŸÑƒÑ‚Ð¸ Ðº Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´Ñƒ
FRONTEND_DIR = os.path.join(PROJECT_ROOT, "frontend")
STATIC_DIR = os.path.join(FRONTEND_DIR, "static")
TEMPLATES_DIR = os.path.join(FRONTEND_DIR, "templates")

print(f"ðŸ” ÐŸÐ¾Ð¸ÑÐº Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹:")
print(f"   BASE_DIR: {BASE_DIR}")
print(f"   ML_SERVICE_DIR: {ML_SERVICE_DIR}")
print(f"   PROJECT_ROOT: {PROJECT_ROOT}")
print(f"   FRONTEND_DIR: {FRONTEND_DIR}")
print(f"   STATIC_DIR: {STATIC_DIR}")
print(f"   TEMPLATES_DIR: {TEMPLATES_DIR}")

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹
if os.path.exists(STATIC_DIR):
    print(f"âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ static: {STATIC_DIR}")
else:
    print(f"âŒ Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ static Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°: {STATIC_DIR}")

if os.path.exists(TEMPLATES_DIR):
    print(f"âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ templates: {TEMPLATES_DIR}")
else:
    print(f"âŒ Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ templates Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°: {TEMPLATES_DIR}")

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚Ð¸ Ð² sys.path Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
sys.path.append(BASE_DIR)
sys.path.append(ML_SERVICE_DIR)

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹ (Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ Ð¾ÑˆÐ¸Ð±Ð¾Ðº)
try:
    from app.ml.patient_data import patient_manager
    print("âœ… ÐœÐ¾Ð´ÑƒÐ»ÑŒ patient_data Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½")
except ImportError as e:
    print(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ patient_data: {e}")
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ
    class PatientManagerStub:
        def get_patient_info(self, *args, **kwargs):
            return {
                "age": 30,
                "gestation_weeks": 32,
                "diagnosis": "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾",
                "has_diabetes": False,
                "has_anemia": False,
                "has_hypertension": False,
                "risk_factors": {},
                "Ph": 7.4,
                "Glu": 5.0,
                "LAC": 1.0,
                "BE": 0.0,
                "CO2": 25.0
            }
    patient_manager = PatientManagerStub()

try:
    from app.ml.report_generator import report_generator
    print("âœ… ÐœÐ¾Ð´ÑƒÐ»ÑŒ report_generator Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½")
except ImportError as e:
    print(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ report_generator: {e}")
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ
    class ReportGeneratorStub:
        def generate_session_report(self, *args, **kwargs):
            return "/tmp/report.pdf"
    report_generator = ReportGeneratorStub()

try:
    from app.auth import router as auth_router
    print("âœ… ÐœÐ¾Ð´ÑƒÐ»ÑŒ auth Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½")
except ImportError as e:
    print(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ auth: {e}")
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ Ð´Ð»Ñ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð°
    from fastapi import APIRouter
    auth_router = APIRouter()

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð¸Ð· stream.py Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
try:
    from app.stream import scan_sessions, prepare_session
    print("âœ… ÐœÐ¾Ð´ÑƒÐ»ÑŒ stream Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½")
except ImportError as e:
    print(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ stream: {e}")
    raise ImportError("ÐœÐ¾Ð´ÑƒÐ»ÑŒ stream Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÐµÐ½ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸")

try:
    from app.patients_search import router as patients_router
    print("âœ… ÐœÐ¾Ð´ÑƒÐ»ÑŒ patients_search Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½")
except ImportError as e:
    print(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ patients_search: {e}")
    from fastapi import APIRouter
    patients_router = APIRouter()

# --------------------
# Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
# --------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ml-service")

# --------------------
# FastAPI app
# --------------------
app = FastAPI(title="Fetal Monitor ML Service")

# CORS (Ð´Ð»Ñ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´Ð°)
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ÐœÐ¾Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð²
if os.path.exists(STATIC_DIR):
    app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")
    print(f"âœ… Ð¡Ñ‚Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ñ‹ Ð¸Ð·: {STATIC_DIR}")
else:
    print(f"âŒ Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ static Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")

if os.path.exists(TEMPLATES_DIR):
    templates = Jinja2Templates(directory=TEMPLATES_DIR)
    print(f"âœ… Ð¨Ð°Ð±Ð»Ð¾Ð½Ñ‹ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ñ‹ Ð¸Ð·: {TEMPLATES_DIR}")
else:
    print(f"âŒ Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ templates Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
    templates = None

# ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð¾Ð²
try:
    app.include_router(auth_router)
    app.include_router(patients_router)
    print("âœ… Ð Ð¾ÑƒÑ‚ÐµÑ€Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ñ‹")
except Exception as e:
    print(f"âš ï¸ ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ: ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ñ‹: {e}")

# --------------------
# Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
# --------------------
def compute_basic_features(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÐµÑÑÐ¸Ð¸.
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· stream.py
    """
    # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¾Ñ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ, Ð¸Ð½Ð°Ñ‡Ðµ ÑÑ‹Ñ€Ñ‹Ðµ
    bpm = df.get("bpm_filtered", df.get("bpm"))
    uterus = df.get("uterus_filtered", df.get("uterus")) if "uterus" in df else None
    
    # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ BPM
    bpm_valid = bpm.dropna()
    
    features = {
        "duration_seconds": float(df["time"].max() - df["time"].min()) if len(df) > 0 else 0,
        "total_samples": len(df),
        "bpm_samples": len(bpm_valid),
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ BPM
        "mean_bpm": float(bpm_valid.mean()) if len(bpm_valid) > 0 else None,
        "median_bpm": float(bpm_valid.median()) if len(bpm_valid) > 0 else None,
        "max_bpm": float(bpm_valid.max()) if len(bpm_valid) > 0 else None,
        "min_bpm": float(bpm_valid.min()) if len(bpm_valid) > 0 else None,
        "std_bpm": float(bpm_valid.std()) if len(bpm_valid) > 0 else None,
        
        # Ð¡Ð¾Ð±Ñ‹Ñ‚Ð¸Ñ (ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ðµ)
        "decel_count": 0,  # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ°
        "tachy_count": len(bpm_valid[bpm_valid > 160]) if len(bpm_valid) > 0 else 0,
        "brady_count": len(bpm_valid[bpm_valid < 110]) if len(bpm_valid) > 0 else 0,
    }
    
    return features

# --------------------
# Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÐºÐ»Ð°ÑÑÑ‹ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹
# --------------------
class SimpleTrendPredictor:
    """ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒ Ñ‚Ñ€ÐµÐ½Ð´Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    def __init__(self, window_size: int = 50):
        self.window_size = window_size
        self.bpm_buffer = []
        self.time_buffer = []
        
    def update(self, time_val: float, bpm_val: Optional[float]):
        if bpm_val is not None and not np.isnan(bpm_val):
            self.time_buffer.append(time_val)
            self.bpm_buffer.append(bpm_val)
            # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð±ÑƒÑ„ÐµÑ€Ð°
            if len(self.time_buffer) > self.window_size:
                self.time_buffer.pop(0)
                self.bpm_buffer.pop(0)
            
    def predict_trend(self) -> Dict:
        if len(self.bpm_buffer) < 10:
            return {"trend": "insufficient_data", "slope": 0.0, "confidence": 0.0}
            
        times = np.array(self.time_buffer)
        bpm = np.array(self.bpm_buffer)
        
        # Ð›Ð¸Ð½ÐµÐ¹Ð½Ð°Ñ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ñ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ñ‚Ñ€ÐµÐ½Ð´Ð°
        try:
            # Ð¦ÐµÐ½Ñ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð´Ð»Ñ Ñ‡Ð¸ÑÐ»ÐµÐ½Ð½Ð¾Ð¹ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
            times_centered = times - np.mean(times)
            
            # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð»Ð¸Ð½ÐµÐ¹Ð½Ð°Ñ Ñ€ÐµÐ³Ñ€ÐµÑÑÐ¸Ñ
            if np.sum(times_centered ** 2) == 0:
                slope = 0.0
            else:
                slope = np.sum(times_centered * bpm) / np.sum(times_centered ** 2)
            
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ñ€ÐµÐ½Ð´
            if slope > 0.05:
                trend = "rising"
            elif slope < -0.05:
                trend = "falling" 
            else:
                trend = "stable"
                
            # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
            confidence = min(1.0, len(self.bpm_buffer) / self.window_size)
            
            return {
                "trend": trend,
                "slope": float(slope),
                "confidence": float(confidence),
                "window_size": len(self.bpm_buffer)
            }
        except Exception as e:
            logger.warning(f"Error in trend prediction: {e}")
            return {"trend": "error", "slope": 0.0, "confidence": 0.0}

class RiskPredictor:
    """ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ñ€Ð¸ÑÐºÐ¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»"""
    def __init__(self):
        pass
        
    def predict_risk(self, bpm_values: List[float]) -> Dict:
        if len(bpm_values) < 10:
            return {"risk_level": "unknown", "score": 0.0, "factors": []}
            
        current_bpm = bpm_values[-1] if bpm_values else 0
        bpm_std = np.std(bpm_values) if len(bpm_values) > 1 else 0
        
        risk_score = 0.0
        factors = []
        
        # ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ñ€Ð¸ÑÐºÐ°
        if current_bpm > 160:
            risk_score += 0.4
            factors.append("tachycardia")
        elif current_bpm < 110:
            risk_score += 0.5
            factors.append("bradycardia")
            
        if bpm_std > 15:
            risk_score += 0.3
            factors.append("high_variability")
        elif bpm_std < 3:
            risk_score += 0.2
            factors.append("low_variability")
                
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ñ€Ð¸ÑÐºÐ°
        if risk_score >= 0.6:
            risk_level = "high"
        elif risk_score >= 0.3:
            risk_level = "medium"
        else:
            risk_level = "low"
            
        return {
            "risk_level": risk_level,
            "score": float(risk_score),
            "factors": factors,
            "current_bpm": float(current_bpm),
            "variability": float(bpm_std)
        }

class RiskPredictor:
    """ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ñ€Ð¸ÑÐºÐ¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»"""
    def __init__(self):
        pass
        
    def predict_risk(self, bpm_values: List[float]) -> Dict:
        if len(bpm_values) < 10:
            return {"risk_level": "unknown", "score": 0.0, "factors": []}
            
        current_bpm = bpm_values[-1] if bpm_values else 0
        bpm_std = np.std(bpm_values) if len(bpm_values) > 1 else 0
        
        risk_score = 0.0
        factors = []
        
        # ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ñ€Ð¸ÑÐºÐ°
        if current_bpm > 160:
            risk_score += 0.4
            factors.append("tachycardia")
        elif current_bpm < 110:
            risk_score += 0.5
            factors.append("bradycardia")
            
        if bpm_std > 15:
            risk_score += 0.3
            factors.append("high_variability")
        elif bpm_std < 3:
            risk_score += 0.2
            factors.append("low_variability")
                
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ñ€Ð¸ÑÐºÐ°
        if risk_score >= 0.6:
            risk_level = "high"
        elif risk_score >= 0.3:
            risk_level = "medium"
        else:
            risk_level = "low"
            
        return {
            "risk_level": risk_level,
            "score": float(risk_score),
            "factors": factors,
            "current_bpm": float(current_bpm),
            "variability": float(bpm_std)
        }

def clean_for_json(data):
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ JSON ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸"""
    import math
    import numpy as np
    
    if isinstance(data, dict):
        return {k: clean_for_json(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [clean_for_json(v) for v in data]
    elif isinstance(data, (float, np.floating)):
        if math.isnan(data) or math.isinf(data):
            return None
        return float(data)
    elif isinstance(data, (np.integer,)):
        return int(data)
    else:
        return data

# --------------------
# REST endpoints
# --------------------
@app.get("/")
async def root(request: Request):
    if templates:
        return templates.TemplateResponse("main.html", {"request": request})
    else:
        return JSONResponse({"message": "Fetal Monitor ML Service", "status": "running", "templates": "not available"})

@app.get("/kgt-monitoring")
async def kgt_monitoring(request: Request):
    if templates:
        return templates.TemplateResponse("startKGT.html", {"request": request})
    else:
        return JSONResponse({"message": "KGT Monitoring", "status": "running", "templates": "not available"})

@app.get("/api/ping")
def ping():
    return {"msg": "pong", "status": "success"}

@app.get("/api/sessions")
def list_sessions():
    """Ð’ÐµÑ€Ð½ÑƒÑ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¹ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    try:
        sessions = scan_sessions()
        result = [
            {"session_id": sid, "group": info.group, "folder_id": info.folder_id}
            for sid, info in sessions.items()
        ]
        print(f"ðŸ“‹ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ ÑÐµÑÑÐ¸Ð¹ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {len(result)}")
        return result
    except Exception as e:
        logger.error(f"Error listing sessions: {e}")
        return []

@app.get("/api/sessions/{sid}")
def session_info(sid: str, sample_rate: float = Query(4.0, description="Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸, Ð“Ñ†")):
    """ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    try:
        sessions = scan_sessions()
        if sid not in sessions:
            raise HTTPException(status_code=404, detail="Session not found")
        prepared = prepare_session(sessions[sid], sample_rate=sample_rate)
        return {
            "meta": prepared["meta"],
            "n_samples": len(prepared["merged"]),
            "warnings": prepared["warnings"],
        }
    except Exception as e:
        logger.error(f"Error getting session info: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/sessions/{sid}/analysis")
def session_analysis(sid: str, sample_rate: float = Query(4.0)):
    """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐµÑÑÐ¸Ð¸ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚ÐºÐ¸ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    sessions = scan_sessions()
    if sid not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    prepared = prepare_session(sessions[sid], sample_rate=sample_rate)
    df = prepared["merged"]

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚ÐºÐ¸
    session_info = sessions[sid]
    patient_info = patient_manager.get_patient_info(
        session_info.folder_id, 
        session_info.group
    )

    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ñ„Ð¸Ñ‡Ð¸ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚ÐºÐ¸
    features = compute_basic_features(df)
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚ÐºÐµ Ð² Ð¾Ñ‚Ð²ÐµÑ‚
    response_data = {
        "meta": prepared["meta"],
        "features": features,
        "patient_info": {
            "age": patient_info.get("age"),
            "gestation_weeks": patient_info.get("gestation_weeks"),
            "diagnosis": patient_info.get("diagnosis"),
            "has_diabetes": patient_info.get("has_diabetes"),
            "has_anemia": patient_info.get("has_anemia"),
            "has_hypertension": patient_info.get("has_hypertension"),
            "risk_factors": patient_info.get("risk_factors", {}),
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ðµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
            "Ph": patient_info.get("Ph"),
            "Glu": patient_info.get("Glu"), 
            "LAC": patient_info.get("LAC"),
            "BE": patient_info.get("BE"),
            "CO2": patient_info.get("CO2")
        }
    }

    clean_response = clean_for_json(response_data)
    return clean_response

@app.get("/api/sessions/{sid}/patient-info")
def get_patient_info(sid: str):
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚ÐºÐµ"""
    sessions = scan_sessions()
    if sid not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session_info = sessions[sid]
    patient_info = patient_manager.get_patient_info(
        session_info.folder_id, 
        session_info.group
    )
    
    return {
        "session_id": sid,
        "folder_id": session_info.folder_id,
        "group": session_info.group,
        "patient_info": patient_info
    }

# --------------------
# WebSocket streaming Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸ÑÐ¼Ð¸ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
# --------------------
@app.websocket("/ws/stream/{sid}")
async def websocket_stream(websocket: WebSocket, sid: str, sample_rate: float = 4.0):
    """
    Ð¡Ñ‚Ñ€Ð¸Ð¼ Ð Ð•ÐÐ›Ð¬ÐÐ«Ð¥ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸ÑÐ¼Ð¸ Ð¸Ð· CSV Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· stream.py
    """
    await websocket.accept()
    sessions = scan_sessions()

    if sid not in sessions:
        await websocket.send_json({"error": f"Session {sid} not found"})
        await websocket.close()
        return

    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ‡ÐµÑ€ÐµÐ· stream.py
    prepared = prepare_session(sessions[sid], sample_rate=sample_rate)
    merged = prepared["merged"]

    # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
    print(f"ðŸ“Š Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {len(merged)} ÑÑ‚Ñ€Ð¾Ðº")
    print(f"ðŸ“Š ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸: {merged.columns.tolist()}")
    
    if not merged.empty:
        bpm_data = merged.get("bpm", merged.get("bpm_filtered"))
        if bpm_data is not None:
            bpm_valid = bpm_data.dropna()
            print(f"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð§Ð¡Ð¡: samples={len(bpm_valid)}, min={bpm_valid.min()}, max={bpm_valid.max()}, mean={bpm_valid.mean():.1f}")
        
        uterus_data = merged.get("uterus", merged.get("uterus_filtered"))
        if uterus_data is not None:
            uterus_valid = uterus_data.dropna()
            print(f"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð¸Ð¹: samples={len(uterus_valid)}, min={uterus_valid.min()}, max={uterus_valid.max()}, mean={uterus_valid.mean():.1f}")

    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
    trend_predictor = SimpleTrendPredictor(window_size=100)
    risk_predictor = RiskPredictor()
    
    # Ð˜ÐÐ˜Ð¦Ð˜ÐÐ›Ð˜Ð—Ð˜Ð Ð£Ð•Ðœ Ð’Ð¡Ð• Ð‘Ð£Ð¤Ð•Ð Ð« - Ð”ÐžÐ‘ÐÐ’Ð¬Ð¢Ð• Ð­Ð¢Ðž
    bpm_buffer = []  # Ð”Ð›Ð¯ ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐ¢Ð•Ð›Ð•Ð™
    bpm_history = []  # Ð”Ð›Ð¯ ÐœÐ•Ð¢Ð Ð˜Ðš
    prediction_history = []  # Ð”Ð›Ð¯ ÐœÐ•Ð¢Ð Ð˜Ðš
    
    # Ð‘ÑƒÑ„ÐµÑ€ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
    prediction_interval = 2.0  # ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸ÑÐ¼Ð¸
    last_prediction_time = 0.0

    # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ
    await websocket.send_json({
        "type": "meta",
        "meta": prepared["meta"], 
        "warnings": prepared["warnings"],
        "data_info": {
            "total_samples": len(merged),
            "columns": merged.columns.tolist(),
            "sample_rate": sample_rate,
            "has_real_data": True
        }
    })

    step = 1.0 / sample_rate
    
    try:
        for index, row in merged.iterrows():
            current_time = float(row["time"])
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð Ð•ÐÐ›Ð¬ÐÐ«Ð• Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· CSV
            bpm_val = None
            if 'bpm' in row and not pd.isna(row['bpm']):
                bpm_val = float(row['bpm'])
            elif 'bpm_filtered' in row and not pd.isna(row['bpm_filtered']):
                bpm_val = float(row['bpm_filtered'])
            
            uterus_val = None
            if 'uterus' in row and not pd.isna(row['uterus']):
                uterus_val = float(row['uterus'])
            elif 'uterus_filtered' in row and not pd.isna(row['uterus_filtered']):
                uterus_val = float(row['uterus_filtered'])
            
            # ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…
            payload = {
                "type": "frame",
                "time": current_time,
                "bpm": bpm_val,
                "uterus": uterus_val,
                "index": index
            }
            await websocket.send_json(payload)

            # ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ ÐœÐ•Ð¢Ð Ð˜Ðš
            if bpm_val is not None:
                bpm_history.append(bpm_val)
                
                # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸
                if len(bpm_history) > 1000:
                    bpm_history.pop(0)
                
                # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 100 Ñ‚Ð¾Ñ‡ÐµÐº
                if len(bpm_history) % 100 == 0:
                    print(f"\nðŸ”„ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ {len(bpm_history)} Ñ‚Ð¾Ñ‡ÐµÐº Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
                    simple_metrics.calculate_and_print_metrics(bpm_history, prediction_history)

            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
            if bpm_val is not None:
                trend_predictor.update(current_time, bpm_val)
                bpm_buffer.append(bpm_val)  # Ð¢Ð•ÐŸÐ•Ð Ð¬ bpm_buffer Ð˜ÐÐ˜Ð¦Ð˜ÐÐ›Ð˜Ð—Ð˜Ð ÐžÐ’ÐÐ
                # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð±ÑƒÑ„ÐµÑ€Ð°
                if len(bpm_buffer) > 200:
                    bpm_buffer.pop(0)

            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 2 ÑÐµÐºÑƒÐ½Ð´Ñ‹
            if current_time - last_prediction_time >= prediction_interval and len(bpm_buffer) >= 10:
                # Ð¢Ñ€ÐµÐ½Ð´Ð¾Ð²Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
                trend_pred = trend_predictor.predict_trend()
                
                # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ€Ð¸ÑÐºÐ¾Ð²
                risk_pred = risk_predictor.predict_risk(bpm_buffer)
                
                # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
                current_stats = {
                    "mean_bpm_1min": float(np.mean(bpm_buffer[-60:])) if len(bpm_buffer) >= 60 else float(np.mean(bpm_buffer)),
                    "median_bpm_1min": float(np.median(bpm_buffer[-60:])) if len(bpm_buffer) >= 60 else float(np.median(bpm_buffer)),
                    "current_bpm": bpm_val,
                    "samples_in_buffer": len(bpm_buffer),
                    "bpm_std": float(np.std(bpm_buffer)) if len(bpm_buffer) > 1 else 0.0
                }
                
                # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð°ÐºÐµÑ‚ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹
                prediction_packet = {
                    "type": "prediction",
                    "timestamp": current_time,
                    "trend": trend_pred,
                    "risk": risk_pred,
                    "statistics": current_stats
                }
                await websocket.send_json(prediction_packet)
                
                # ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐÐ˜Ð™ Ð”Ð›Ð¯ ÐœÐ•Ð¢Ð Ð˜Ðš
                prediction_history.append(prediction_packet)
                if len(prediction_history) > 200:
                    prediction_history.pop(0)
                
                last_prediction_time = current_time

            await asyncio.sleep(step)

    except WebSocketDisconnect:
        logger.info(f"ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð¸Ð»ÑÑ Ð¾Ñ‚ {sid}")
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² WebSocket Ð¿Ð¾Ñ‚Ð¾ÐºÐµ: {e}")
        await websocket.send_json({"type": "error", "message": str(e)})

# --------------------
# ÐÐ¾Ð²Ñ‹Ðµ endpoint'Ñ‹ Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð° ÑÐµÑÑÐ¸Ð¸
# --------------------
@app.get("/api/available-sessions")
async def get_available_sessions():
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¹ Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    try:
        sessions = scan_sessions()
        print(f"ðŸ” ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÐµÑÑÐ¸Ð¹ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {len(sessions)}")
        
        # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÐ¼ ÑÐµÑÑÐ¸Ð¸ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ñƒ Ð¸ Ð¿Ð°Ð¿ÐºÐµ
        grouped_sessions = {}
        
        for session_id, session_info in sessions.items():
            group = getattr(session_info, 'group', 'unknown')
            folder_id = getattr(session_info, 'folder_id', 'unknown')
            
            group_key = f"{group}_{folder_id}"
            if group_key not in grouped_sessions:
                grouped_sessions[group_key] = {
                    "group": group,
                    "folder_id": folder_id,
                    "sessions": []
                }
            grouped_sessions[group_key]["sessions"].append({
                "session_id": session_id,
                "duration": "30 Ð¼Ð¸Ð½ÑƒÑ‚"  # ÐœÐ¾Ð¶Ð½Ð¾ Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÑŒ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
            })
        
        result = list(grouped_sessions.values())
        print(f"ðŸ“Š Ð¡Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÐµÑÑÐ¸Ð¸: {len(result)} Ð³Ñ€ÑƒÐ¿Ð¿")
        return result
        
    except Exception as e:
        logger.error(f"Error getting available sessions: {e}")
        return [{"group": "regular", "folder_id": "1", "sessions": [{"session_id": "1", "duration": "30 Ð¼Ð¸Ð½ÑƒÑ‚"}]}]

@app.post("/api/select-session")
async def select_session(request: Request):
    """Ð’Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
    try:
        data = await request.json()
        session_id = data.get("session_id")
        
        if not session_id:
            raise HTTPException(status_code=400, detail="Session ID is required")
        
        sessions = scan_sessions()
        if session_id not in sessions:
            raise HTTPException(status_code=404, detail="Session not found")
        
        return {"status": "success", "session_id": session_id}
    except Exception as e:
        logger.error(f"Error selecting session: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    
# Ð¥Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¹ Ð² Ð¿Ð°Ð¼ÑÑ‚Ð¸
uploaded_sessions = {}

@app.get("/api/uploaded-sessions")
def list_uploaded_sessions():
    """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¹"""
    return list(uploaded_sessions.values())

@app.post("/api/upload-kgt")
async def upload_kgt(
    file: UploadFile = File(...),
    patient_name: str = Form("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚"),
    session_duration: str = Form("30 Ð¼Ð¸Ð½ÑƒÑ‚")
):
    """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐšÐ“Ð¢ Ñ„Ð°Ð¹Ð»Ð° Ñ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð°"""
    try:
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð°ÐºÐ¾Ð²ÐºÐ¸
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
            file_path = temp_path / file.filename
            with open(file_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ Ñ„Ð°Ð¹Ð» Ð°Ñ€Ñ…Ð¸Ð²Ð¾Ð¼
            if file.filename.endswith('.zip'):
                # Ð Ð°ÑÐ¿Ð°ÐºÐ¾Ð²Ñ‹Ð²Ð°ÐµÐ¼ Ð°Ñ€Ñ…Ð¸Ð²
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    zip_ref.extractall(temp_path)
                
                # Ð˜Ñ‰ÐµÐ¼ CSV Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ñ€Ð°ÑÐ¿Ð°ÐºÐ¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð°Ñ…
                csv_files = list(temp_path.glob("**/*.csv"))
                if not csv_files:
                    raise HTTPException(status_code=400, detail="Ð’ Ð°Ñ€Ñ…Ð¸Ð²Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ CSV Ñ„Ð°Ð¹Ð»Ñ‹")
                
                # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ð¹ CSV Ñ„Ð°Ð¹Ð»
                data_file = csv_files[0]
            else:
                data_file = file_path
            
            # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· CSV Ñ„Ð°Ð¹Ð»Ð°
            df = pd.read_csv(data_file)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸
            required_columns = ['time', 'bpm']
            if not all(col in df.columns for col in required_columns):
                raise HTTPException(
                    status_code=400, 
                    detail=f"CSV Ñ„Ð°Ð¹Ð» Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸: {required_columns}"
                )
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
            processed_data = process_uploaded_kgt_data(df)
            
            # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ID Ð´Ð»Ñ ÑÐµÑÑÐ¸Ð¸
            session_id = str(uuid.uuid4())
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ Ð² Ð¿Ð°Ð¼ÑÑ‚Ð¸ (Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸ - Ð² Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…)
            uploaded_sessions[session_id] = {
                "session_id": session_id,
                "patient_name": patient_name,
                "session_duration": session_duration,
                "upload_time": datetime.now().isoformat(),
                "data": processed_data,
                "original_filename": file.filename,
                "data_points": len(processed_data)
            }
            
            return {
                "status": "success",
                "session_id": session_id,
                "patient_name": patient_name,
                "data_points": len(processed_data),
                "duration_seconds": len(processed_data) / 4.0  # ÐŸÑ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼ 4 Ð“Ñ†
            }
            
    except Exception as e:
        logger.error(f"Error uploading KGT file: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ð°: {str(e)}")

def process_uploaded_kgt_data(df: pd.DataFrame) -> List[Dict]:
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… ÐšÐ“Ð¢"""
    processed_data = []
    
    for index, row in df.iterrows():
        data_point = {
            "time": float(row.get("time", index / 4.0)),  # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 4 Ð“Ñ†
            "bpm": float(row.get("bpm", 0)),
            "uterus": float(row.get("uterus", row.get("contractions", 0))),
            "index": index
        }
        processed_data.append(data_point)
    
    return processed_data

# Ð¥Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¹ Ð² Ð¿Ð°Ð¼ÑÑ‚Ð¸
uploaded_sessions = {}

@app.get("/api/uploaded-sessions")
def list_uploaded_sessions():
    """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¹"""
    return list(uploaded_sessions.values())

@app.websocket("/ws/stream/uploaded/{session_id}")
async def websocket_stream_uploaded(websocket: WebSocket, session_id: str, sample_rate: float = 4.0):
    """Ð¡Ñ‚Ñ€Ð¸Ð¼ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… ÐšÐ“Ð¢ Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸"""
    await websocket.accept()
    
    if session_id not in uploaded_sessions:
        await websocket.send_json({"error": f"Uploaded session {session_id} not found"})
        await websocket.close()
        return
    
    session_data = uploaded_sessions[session_id]
    
    try:
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ‡ÐµÑ€ÐµÐ· stream.py
        prepared = session_data["prepared_data"]
        merged = prepared["merged"]
        
        logger.info(f"ÐÐ°Ñ‡Ð°Ð»Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð° Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸: {len(merged)} Ñ‚Ð¾Ñ‡ÐµÐº Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
        trend_predictor = SimpleTrendPredictor(window_size=100)
        risk_predictor = RiskPredictor()
        
        # Ð˜ÐÐ˜Ð¦Ð˜ÐÐ›Ð˜Ð—Ð˜Ð Ð£Ð•Ðœ Ð’Ð¡Ð• Ð‘Ð£Ð¤Ð•Ð Ð«
        bpm_buffer = []  # Ð”Ð›Ð¯ ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐ¢Ð•Ð›Ð•Ð™
        bpm_history = []  # Ð”Ð›Ð¯ ÐœÐ•Ð¢Ð Ð˜Ðš
        prediction_history = []  # Ð”Ð›Ð¯ ÐœÐ•Ð¢Ð Ð˜Ðš
        
        # Ð‘ÑƒÑ„ÐµÑ€ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        prediction_interval = 2.0
        last_prediction_time = 0.0
        
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
        await websocket.send_json({
            "type": "meta",
            "meta": {
                "patient_name": session_data["patient_name"],
                "session_duration": f"{len(merged) / 4.0 / 60:.1f} Ð¼Ð¸Ð½ÑƒÑ‚",
                "data_points": len(merged),
                "source": "folder_upload",
                "original_filename": session_data.get("original_filename", "Unknown")
            },
            "data_info": {
                "total_samples": len(merged),
                "sample_rate": sample_rate,
                "has_real_data": True
            }
        })
        
        step = 1.0 / sample_rate
        
        for index, row in merged.iterrows():
            current_time = float(row["time"])
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ DataFrame
            bpm_val = None
            if 'bpm_filtered' in row and not pd.isna(row['bpm_filtered']):
                bpm_val = float(row['bpm_filtered'])
            elif 'bpm' in row and not pd.isna(row['bpm']):
                bpm_val = float(row['bpm'])
            
            uterus_val = None
            if 'uterus_filtered' in row and not pd.isna(row['uterus_filtered']):
                uterus_val = float(row['uterus_filtered'])
            elif 'uterus' in row and not pd.isna(row['uterus']):
                uterus_val = float(row['uterus'])
            
            # ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…
            payload = {
                "type": "frame",
                "time": current_time,
                "bpm": bpm_val,
                "uterus": uterus_val,
                "index": index
            }
            await websocket.send_json(payload)
            
            # ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ ÐœÐ•Ð¢Ð Ð˜Ðš
            if bpm_val is not None:
                bpm_history.append(bpm_val)
                
                if len(bpm_history) > 1000:
                    bpm_history.pop(0)
                
                if len(bpm_history) % 100 == 0:
                    print(f"\nðŸ”„ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ {len(bpm_history)} Ñ‚Ð¾Ñ‡ÐµÐº Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
                    simple_metrics.calculate_and_print_metrics(bpm_history, prediction_history)
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
            if bpm_val is not None:
                trend_predictor.update(current_time, bpm_val)
                bpm_buffer.append(bpm_val)  # Ð¢Ð•ÐŸÐ•Ð Ð¬ bpm_buffer Ð˜ÐÐ˜Ð¦Ð˜ÐÐ›Ð˜Ð—Ð˜Ð ÐžÐ’ÐÐ
                if len(bpm_buffer) > 200:
                    bpm_buffer.pop(0)
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
            if current_time - last_prediction_time >= prediction_interval and len(bpm_buffer) >= 10:
                trend_pred = trend_predictor.predict_trend()
                risk_pred = risk_predictor.predict_risk(bpm_buffer)
                
                current_stats = {
                    "mean_bpm_1min": float(np.mean(bpm_buffer[-60:])) if len(bpm_buffer) >= 60 else float(np.mean(bpm_buffer)),
                    "median_bpm_1min": float(np.median(bpm_buffer[-60:])) if len(bpm_buffer) >= 60 else float(np.median(bpm_buffer)),
                    "current_bpm": bpm_val,
                    "samples_in_buffer": len(bpm_buffer),
                    "bpm_std": float(np.std(bpm_buffer)) if len(bpm_buffer) > 1 else 0.0
                }
                
                prediction_packet = {
                    "type": "prediction",
                    "timestamp": current_time,
                    "trend": trend_pred,
                    "risk": risk_pred,
                    "statistics": current_stats
                }
                await websocket.send_json(prediction_packet)
                
                # ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐÐ˜Ð™ Ð”Ð›Ð¯ ÐœÐ•Ð¢Ð Ð˜Ðš
                prediction_history.append(prediction_packet)
                if len(prediction_history) > 200:
                    prediction_history.pop(0)
                
                last_prediction_time = current_time
            
            await asyncio.sleep(step)
            
    except WebSocketDisconnect:
        logger.info(f"ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð¸Ð»ÑÑ Ð¾Ñ‚ uploaded session {session_id}")
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² WebSocket Ð¿Ð¾Ñ‚Ð¾ÐºÐµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
        await websocket.send_json({"type": "error", "message": str(e)})

@app.post("/api/upload-kgt-zip")
async def upload_kgt_zip(
    file: UploadFile = File(...),
    patient_name: str = Form("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚")
):
    """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐšÐ“Ð¢ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· ZIP Ð°Ñ€Ñ…Ð¸Ð²Ð° Ñ Ð¿Ð°Ð¿ÐºÐ°Ð¼Ð¸ bpm Ð¸ uterus"""
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð» ÑÐ²Ð»ÑÐµÑ‚ÑÑ ZIP Ð°Ñ€Ñ…Ð¸Ð²Ð¾Ð¼
        if not file.filename.lower().endswith('.zip'):
            raise HTTPException(status_code=400, detail="Ð¤Ð°Ð¹Ð» Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ ZIP Ð°Ñ€Ñ…Ð¸Ð²Ð¾Ð¼")
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð°ÐºÐ¾Ð²ÐºÐ¸
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ð¹ ZIP Ñ„Ð°Ð¹Ð»
            zip_path = temp_path / file.filename
            with open(zip_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            logger.info(f"ZIP Ñ„Ð°Ð¹Ð» ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {zip_path}")
            
            # Ð Ð°ÑÐ¿Ð°ÐºÐ¾Ð²Ñ‹Ð²Ð°ÐµÐ¼ Ð°Ñ€Ñ…Ð¸Ð²
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(temp_path)
            
            logger.info(f"ZIP Ð°Ñ€Ñ…Ð¸Ð² Ñ€Ð°ÑÐ¿Ð°ÐºÐ¾Ð²Ð°Ð½ Ð²: {temp_path}")
            
            # Ð˜Ñ‰ÐµÐ¼ Ð¿Ð°Ð¿ÐºÐ¸ bpm Ð¸ uterus Ð² Ñ€Ð°ÑÐ¿Ð°ÐºÐ¾Ð²Ð°Ð½Ð½Ð¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ
            bpm_files = []
            uterus_files = []
            
            # Ð˜Ñ‰ÐµÐ¼ Ð²ÑÐµ CSV Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐ°Ñ… bpm Ð¸ uterus
            for csv_file in temp_path.glob("**/bpm/*.csv"):
                bpm_files.append(str(csv_file))
                logger.info(f"ÐÐ°Ð¹Ð´ÐµÐ½ BPM Ñ„Ð°Ð¹Ð»: {csv_file}")
            
            for csv_file in temp_path.glob("**/uterus/*.csv"):
                uterus_files.append(str(csv_file))
                logger.info(f"ÐÐ°Ð¹Ð´ÐµÐ½ Uterus Ñ„Ð°Ð¹Ð»: {csv_file}")
            
            # ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº - ÐµÑÐ»Ð¸ Ð¿Ð°Ð¿ÐºÐ¸ Ð½Ð°Ñ…Ð¾Ð´ÑÑ‚ÑÑ Ð² ÐºÐ¾Ñ€Ð½Ðµ
            if not bpm_files:
                bpm_dir = temp_path / "bpm"
                if bpm_dir.exists():
                    for csv_file in bpm_dir.glob("*.csv"):
                        bpm_files.append(str(csv_file))
                        logger.info(f"ÐÐ°Ð¹Ð´ÐµÐ½ BPM Ñ„Ð°Ð¹Ð» (Ð² ÐºÐ¾Ñ€Ð½Ðµ): {csv_file}")
            
            if not uterus_files:
                uterus_dir = temp_path / "uterus"
                if uterus_dir.exists():
                    for csv_file in uterus_dir.glob("*.csv"):
                        uterus_files.append(str(csv_file))
                        logger.info(f"ÐÐ°Ð¹Ð´ÐµÐ½ Uterus Ñ„Ð°Ð¹Ð» (Ð² ÐºÐ¾Ñ€Ð½Ðµ): {csv_file}")
            
            if not bpm_files and not uterus_files:
                # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ð°Ñ€Ñ…Ð¸Ð²Ð° Ð´Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ¸
                archive_structure = []
                for item in temp_path.rglob("*"):
                    if item.is_file():
                        archive_structure.append(str(item.relative_to(temp_path)))
                
                logger.error(f"Ð’ Ð°Ñ€Ñ…Ð¸Ð²Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ CSV Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐ°Ñ… bpm/uterus. Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð°Ñ€Ñ…Ð¸Ð²Ð°: {archive_structure}")
                raise HTTPException(
                    status_code=400, 
                    detail="Ð’ Ð°Ñ€Ñ…Ð¸Ð²Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ CSV Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐ°Ñ… bpm Ð¸ uterus. ÐÑ€Ñ…Ð¸Ð² Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ Ð¿Ð°Ð¿ÐºÐ¸ 'bpm' Ð¸ 'uterus' Ñ CSV Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸."
                )
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ SessionInfo Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‡ÐµÑ€ÐµÐ· stream.py
            session_info = create_session_from_files(bpm_files, uterus_files, patient_name)
            
            if not session_info:
                raise HTTPException(status_code=400, detail="ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð¾Ð²")
            
            # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ Ñ‡ÐµÑ€ÐµÐ· stream.py
            prepared = prepare_session(session_info, sample_rate=4.0)
            
            # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ID Ð´Ð»Ñ ÑÐµÑÑÐ¸Ð¸
            session_id = str(uuid.uuid4())
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ Ð² Ð¿Ð°Ð¼ÑÑ‚Ð¸
            uploaded_sessions[session_id] = {
                "session_id": session_id,
                "patient_name": patient_name,
                "session_info": session_info,
                "prepared_data": prepared,
                "upload_time": datetime.now().isoformat(),
                "data_points": len(prepared["merged"]),
                "source": "zip_upload",
                "original_filename": file.filename
            }
            
            logger.info(f"Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½ ZIP Ð°Ñ€Ñ…Ð¸Ð²: {file.filename}, {len(prepared['merged'])} Ñ‚Ð¾Ñ‡ÐµÐº Ð´Ð°Ð½Ð½Ñ‹Ñ…")
            
            return {
                "status": "success",
                "session_id": session_id,
                "patient_name": patient_name,
                "data_points": len(prepared["merged"]),
                "duration_seconds": len(prepared["merged"]) / 4.0,
                "meta": prepared["meta"]
            }
            
    except zipfile.BadZipFile:
        logger.error(f"ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ ZIP Ñ„Ð°Ð¹Ð»: {file.filename}")
        raise HTTPException(status_code=400, detail="ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ ZIP Ñ„Ð°Ð¹Ð»")
    except Exception as e:
        logger.error(f"Error uploading KGT ZIP: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ZIP Ð°Ñ€Ñ…Ð¸Ð²Ð°: {str(e)}")

def create_session_from_files(bpm_files: List[str], uterus_files: List[str], patient_name: str):
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ SessionInfo Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ¾Ð² Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‡ÐµÑ€ÐµÐ· stream.py"""
    
    if not bpm_files and not uterus_files:
        return None
    
    # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ SessionInfo Ð¸Ð· stream.py
    try:
        from app.stream import SessionInfo
    except ImportError as e:
        logger.error(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ SessionInfo: {e}")
        return None
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ SessionInfo
    session_info = SessionInfo(
        group="uploaded",  # ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð° Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
        folder_id=patient_name.replace(" ", "_"),
        session_id=f"uploaded_{int(datetime.now().timestamp())}",
        bpm_files=sorted(bpm_files),
        uterus_files=sorted(uterus_files)
    )
    
    logger.info(f"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð° ÑÐµÑÑÐ¸Ñ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð¾Ð²: {len(bpm_files)} BPM Ñ„Ð°Ð¹Ð»Ð¾Ð², {len(uterus_files)} uterus Ñ„Ð°Ð¹Ð»Ð¾Ð²")
    
    return session_info

def create_session_from_folder(folder_path: Path, patient_name: str):
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ SessionInfo Ð¸Ð· ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð¿Ð°Ð¿ÐºÐ¸ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‡ÐµÑ€ÐµÐ· stream.py"""
    
    bpm_dir = folder_path / "bpm"
    uterus_dir = folder_path / "uterus"
    
    bpm_files = []
    uterus_files = []
    
    # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ BPM Ñ„Ð°Ð¹Ð»Ñ‹
    if bpm_dir.exists():
        for csv_file in bpm_dir.glob("*.csv"):
            bpm_files.append(str(csv_file))
    
    # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Uterus Ñ„Ð°Ð¹Ð»Ñ‹
    if uterus_dir.exists():
        for csv_file in uterus_dir.glob("*.csv"):
            uterus_files.append(str(csv_file))
    
    if not bpm_files and not uterus_files:
        return None
    
    # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ SessionInfo Ð¸Ð· stream.py
    try:
        from app.stream import SessionInfo
    except ImportError as e:
        logger.error(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ SessionInfo: {e}")
        return None
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ SessionInfo
    session_info = SessionInfo(
        group="uploaded",  # ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð° Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
        folder_id=patient_name.replace(" ", "_"),
        session_id=f"uploaded_{int(datetime.now().timestamp())}",
        bpm_files=sorted(bpm_files),
        uterus_files=sorted(uterus_files)
    )
    
    logger.info(f"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð° ÑÐµÑÑÐ¸Ñ: {len(bpm_files)} BPM Ñ„Ð°Ð¹Ð»Ð¾Ð², {len(uterus_files)} uterus Ñ„Ð°Ð¹Ð»Ð¾Ð²")
    
    return session_info

# WebSocket Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð°Ð¿Ð¾Ðº (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ñ‚Ñƒ Ð¶Ðµ Ð»Ð¾Ð³Ð¸ÐºÑƒ)
@app.websocket("/ws/stream/uploaded/{session_id}")
async def websocket_stream_uploaded(websocket: WebSocket, session_id: str, sample_rate: float = 4.0):
    """Ð¡Ñ‚Ñ€Ð¸Ð¼ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… ÐšÐ“Ð¢ Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸"""
    await websocket.accept()
    
    if session_id not in uploaded_sessions:
        await websocket.send_json({"error": f"Uploaded session {session_id} not found"})
        await websocket.close()
        return
    
    session_data = uploaded_sessions[session_id]
    prepared = session_data["prepared_data"]
    merged = prepared["merged"]
    
    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
    trend_predictor = SimpleTrendPredictor(window_size=100)
    risk_predictor = RiskPredictor()
    
    # Ð‘ÑƒÑ„ÐµÑ€ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
    bpm_buffer = []
    prediction_interval = 2.0
    last_prediction_time = 0.0
    
    # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
    await websocket.send_json({
        "type": "meta",
        "meta": {
            "patient_name": session_data["patient_name"],
            "session_duration": f"{len(merged) / 4.0 / 60:.1f} Ð¼Ð¸Ð½ÑƒÑ‚",
            "data_points": len(merged),
            "source": "folder_upload",
            "folder_path": session_data.get("folder_path", "Unknown")
        },
        "data_info": {
            "total_samples": len(merged),
            "sample_rate": sample_rate,
            "has_real_data": True
        }
    })
    
    step = 1.0 / sample_rate
    
    try:
        for index, row in merged.iterrows():
            current_time = float(row["time"])
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ DataFrame
            bpm_val = None
            if 'bpm' in row and not pd.isna(row['bpm']):
                bpm_val = float(row['bpm'])
            elif 'bpm_filtered' in row and not pd.isna(row['bpm_filtered']):
                bpm_val = float(row['bpm_filtered'])
            
            uterus_val = None
            if 'uterus' in row and not pd.isna(row['uterus']):
                uterus_val = float(row['uterus'])
            elif 'uterus_filtered' in row and not pd.isna(row['uterus_filtered']):
                uterus_val = float(row['uterus_filtered'])
            
            # ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…
            payload = {
                "type": "frame",
                "time": current_time,
                "bpm": bpm_val,
                "uterus": uterus_val,
                "index": index
            }
            await websocket.send_json(payload)
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
            if bpm_val is not None:
                trend_predictor.update(current_time, bpm_val)
                bpm_buffer.append(bpm_val)
                if len(bpm_buffer) > 200:
                    bpm_buffer.pop(0)
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
            if current_time - last_prediction_time >= prediction_interval and len(bpm_buffer) >= 10:
                trend_pred = trend_predictor.predict_trend()
                risk_pred = risk_predictor.predict_risk(bpm_buffer)
                
                current_stats = {
                    "mean_bpm_1min": float(np.mean(bpm_buffer[-60:])) if len(bpm_buffer) >= 60 else float(np.mean(bpm_buffer)),
                    "median_bpm_1min": float(np.median(bpm_buffer[-60:])) if len(bpm_buffer) >= 60 else float(np.median(bpm_buffer)),
                    "current_bpm": bpm_val,
                    "samples_in_buffer": len(bpm_buffer),
                    "bpm_std": float(np.std(bpm_buffer)) if len(bpm_buffer) > 1 else 0.0
                }
                
                prediction_packet = {
                    "type": "prediction",
                    "timestamp": current_time,
                    "trend": trend_pred,
                    "risk": risk_pred,
                    "statistics": current_stats
                }
                await websocket.send_json(prediction_packet)
                last_prediction_time = current_time
            
            await asyncio.sleep(step)
            
    except WebSocketDisconnect:
        logger.info(f"ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð¸Ð»ÑÑ Ð¾Ñ‚ uploaded session {session_id}")
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² WebSocket Ð¿Ð¾Ñ‚Ð¾ÐºÐµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
        await websocket.send_json({"type": "error", "message": str(e)})


@app.get("/api/metrics/ml-detailed")
async def get_ml_detailed_metrics():
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ ML Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸"""
    try:
        if not bpm_history:
            return {"message": "ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº"}
        
        bpm_array = np.array([x for x in bpm_history if x is not None])
        
        if len(bpm_array) == 0:
            return {"message": "ÐÐµÑ‚ Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… BPM"}
        
        # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
        y_true, y_pred, y_pred_proba = simple_metrics._generate_test_predictions(bpm_array, prediction_history)
        
        # Ð Ð°ÑÑ‡ÐµÑ‚ Ð²ÑÐµÑ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)
        
        # Confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        cm_percentage = (cm / cm.sum(axis=1, keepdims=True) * 100).round(1)
        
        # Classification report
        class_report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "basic_metrics": {
                "accuracy": float(accuracy),
                "precision": float(precision),
                "recall": float(recall),
                "f1_score": float(f1),
                "samples_count": len(y_true),
                "classes_count": len(np.unique(y_true))
            },
            "confusion_matrix": {
                "matrix": cm.tolist(),
                "percentage": cm_percentage.tolist(),
                "labels": ["ÐÐ¾Ñ€Ð¼Ð°", "Ð¢Ð°Ñ…Ð¸ÐºÐ°Ñ€Ð´Ð¸Ñ", "Ð‘Ñ€Ð°Ð´Ð¸ÐºÐ°Ñ€Ð´Ð¸Ñ"]
            },
            "class_report": class_report,
            "data_quality": {
                "total_samples": len(bpm_history),
                "valid_samples": len(bpm_array),
                "completeness": len(bpm_array) / len(bpm_history) * 100
            }
        }
        
        # Ð’Ñ‹Ð²Ð¾Ð´ Ð² Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ð»
        print(f"\nðŸŽ¯ Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð• ML ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜:")
        print(f"   Accuracy: {accuracy:.3f}")
        print(f"   Precision: {precision:.3f}")
        print(f"   Recall: {recall:.3f}")
        print(f"   F1-Score: {f1:.3f}")
        print(f"   Confusion Matrix:")
        print(f"   {cm}")
        
        return metrics
        
    except Exception as e:
        logger.error(f"Error calculating detailed ML metrics: {e}")
        return {"error": str(e)}
# --------------------
# Ð—Ð°Ð¿ÑƒÑÐº
# --------------------
if __name__ == "__main__":
    import uvicorn
    print("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº ÑÐµÑ€Ð²ÐµÑ€Ð° Ð½Ð° http://localhost:8001")
    print("ðŸ“Š Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð Ð•ÐÐ›Ð¬ÐÐ«Ð• Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· CSV Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· stream.py")
    uvicorn.run("app.main:app", host="0.0.0.0", port=8001, reload=True)